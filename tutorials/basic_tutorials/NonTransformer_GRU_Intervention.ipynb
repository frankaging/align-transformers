{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295aabd4",
   "metadata": {},
   "source": [
    "## Tutorial of Interventions on Non-transformer Model: GRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9515488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Zhengxuan Wu\"\n",
    "__version__ = \"12/22/2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1769eb",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This tutorials show how to use this library on recurrent neural networks, such as GRUs. The set-ups are pretty much the same as standard transformer-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e6b0e9",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3276f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import transformers\n",
    "    import sys\n",
    "\n",
    "    sys.path.append(\"align-transformers/\")\n",
    "except ModuleNotFoundError:\n",
    "    !git clone https://github.com/frankaging/align-transformers.git\n",
    "    !pip install -r align-transformers/requirements.txt\n",
    "    import sys\n",
    "\n",
    "    sys.path.append(\"align-transformers/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e8a491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-10 15:13:59,567] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from models.basic_utils import embed_to_distrib, top_vals, format_token\n",
    "from models.configuration_intervenable_model import (\n",
    "    IntervenableRepresentationConfig,\n",
    "    IntervenableConfig,\n",
    ")\n",
    "from models.intervenable_base import IntervenableModel\n",
    "from models.interventions import (\n",
    "    VanillaIntervention,\n",
    "    RotatedSpaceIntervention,\n",
    "    LowRankRotatedSpaceIntervention,\n",
    ")\n",
    "from models.gru.modelings_gru import GRUConfig\n",
    "from models.gru.modelings_intervenable_gru import create_gru_classifier\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "from plotnine import (\n",
    "    ggplot,\n",
    "    geom_tile,\n",
    "    aes,\n",
    "    facet_wrap,\n",
    "    theme,\n",
    "    element_text,\n",
    "    geom_bar,\n",
    "    geom_hline,\n",
    "    scale_y_log10,\n",
    ")\n",
    "\n",
    "config, tokenizer, gru = create_gru_classifier(GRUConfig(n_layer=1, h_dim=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd47b0",
   "metadata": {},
   "source": [
    "### Vanilla intervention on multiple time steps\n",
    "Recurrent neural networks like GRUs contain stateful representations, where if we intervene on one state, the causal effects should ripple through later states. Intervening on future states may also block interventions on earlier states if interventions happen in the information bottleneck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf760b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervenable_config = IntervenableConfig(\n",
    "    intervenable_model_type=type(gru),\n",
    "    intervenable_representations=[\n",
    "        IntervenableRepresentationConfig(\n",
    "            0,\n",
    "            \"cell_output\",\n",
    "            \"t\",\n",
    "            1,\n",
    "        ),\n",
    "    ],\n",
    "    intervenable_interventions_type=VanillaIntervention,\n",
    ")\n",
    "intervenable = IntervenableModel(intervenable_config, gru)\n",
    "\n",
    "base = {\"inputs_embeds\": torch.rand(10, 10, 2)}\n",
    "source = {\"inputs_embeds\": torch.rand(10, 10, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36baa475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "_, counterfactual_outputs_all = intervenable(\n",
    "    base,\n",
    "    [source],\n",
    "    {\n",
    "        \"sources->base\": ([[[0, 2, 4]] * 10], [[[0, 5, 7]] * 10])\n",
    "    },  # this suppose to intervene once, but it will be called 10 times.\n",
    ")\n",
    "\n",
    "_, counterfactual_outputs_last = intervenable(\n",
    "    base,\n",
    "    [source],\n",
    "    {\n",
    "        \"sources->base\": ([[[4]] * 10], [[[7]] * 10])\n",
    "    },  # this suppose to intervene once, but it will be called 10 times.\n",
    ")\n",
    "\n",
    "print(torch.equal(counterfactual_outputs_all[0], counterfactual_outputs_last[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f2ba4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "_, counterfactual_outputs_all = intervenable(\n",
    "    base,\n",
    "    [source],\n",
    "    {\n",
    "        \"sources->base\": ([[[0, 2]] * 10], [[[0, 5]] * 10])\n",
    "    },  # this suppose to intervene once, but it will be called 10 times.\n",
    ")\n",
    "\n",
    "_, counterfactual_outputs_last = intervenable(\n",
    "    base,\n",
    "    [source],\n",
    "    {\n",
    "        \"sources->base\": ([[[2]] * 10], [[[5]] * 10])\n",
    "    },  # this suppose to intervene once, but it will be called 10 times.\n",
    ")\n",
    "\n",
    "print(torch.equal(counterfactual_outputs_all[0], counterfactual_outputs_last[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888504d8",
   "metadata": {},
   "source": [
    "### Subspace DAS by intervening a single time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d75ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base tensor([[-0.1404, -0.0601]])\n",
      "source tensor([[0.0034, 0.0207]])\n"
     ]
    }
   ],
   "source": [
    "intervenable_config = IntervenableConfig(\n",
    "    intervenable_model_type=type(gru),\n",
    "    intervenable_representations=[\n",
    "        IntervenableRepresentationConfig(\n",
    "            0,\n",
    "            \"cell_output\",\n",
    "            \"t\",\n",
    "            1,\n",
    "            intervenable_low_rank_dimension=2,\n",
    "        ),\n",
    "    ],\n",
    "    intervenable_interventions_type=LowRankRotatedSpaceIntervention,\n",
    ")\n",
    "intervenable = IntervenableModel(intervenable_config, gru)\n",
    "base = {\"inputs_embeds\": torch.rand(1, 1, 2)}\n",
    "source = {\"inputs_embeds\": torch.rand(1, 1, 2)}\n",
    "print(\"base\", intervenable(base)[0][0])\n",
    "print(\"source\", intervenable(source)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a0846a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0034, 0.0207]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "_, counterfactual_outputs = intervenable(\n",
    "    base, [source], {\"sources->base\": ([[[0]]], [[[0]]])}\n",
    ")\n",
    "print(counterfactual_outputs[0])  # this should be the same as the source output\n",
    "counterfactual_outputs[\n",
    "    0\n",
    "].sum().backward()  # fake call to make sure gradient can be populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91d5beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base tensor([[-0.1157, -0.0500]])\n",
      "source tensor([[0.0614, 0.0535]])\n"
     ]
    }
   ],
   "source": [
    "intervenable_config = IntervenableConfig(\n",
    "    intervenable_model_type=type(gru),\n",
    "    intervenable_representations=[\n",
    "        IntervenableRepresentationConfig(\n",
    "            0,\n",
    "            \"cell_output\",\n",
    "            \"t\",\n",
    "            1,\n",
    "            intervenable_low_rank_dimension=2,\n",
    "            subspace_partition=[[0, 1], [1, 2]],  # partition into two sets of subspaces\n",
    "            intervention_link_key=0,  # linked ones target the same subspace\n",
    "        ),\n",
    "        IntervenableRepresentationConfig(\n",
    "            0,\n",
    "            \"cell_output\",\n",
    "            \"t\",\n",
    "            1,\n",
    "            intervenable_low_rank_dimension=2,\n",
    "            subspace_partition=[[0, 1], [1, 2]],  # partition into two sets of subspaces\n",
    "            intervention_link_key=0,  # linked ones target the same subspace\n",
    "        ),\n",
    "    ],\n",
    "    intervenable_interventions_type=LowRankRotatedSpaceIntervention,\n",
    ")\n",
    "intervenable = IntervenableModel(intervenable_config, gru)\n",
    "\n",
    "base = {\"inputs_embeds\": torch.rand(1, 1, 2)}\n",
    "source = {\"inputs_embeds\": torch.rand(1, 1, 2)}\n",
    "print(\"base\", intervenable(base)[0][0])\n",
    "print(\"source\", intervenable(source)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "979fe5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0614, 0.0535]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "_, counterfactual_outputs = intervenable(\n",
    "    base,\n",
    "    [source, source],\n",
    "    {\"sources->base\": ([[[0]], [[0]]], [[[0]], [[0]]])},\n",
    "    subspaces=[[[0]], [[1]]],\n",
    ")\n",
    "print(counterfactual_outputs[0])  # this should be the same as the source output\n",
    "counterfactual_outputs[\n",
    "    0\n",
    "].sum().backward()  # fake call to make sure gradient can be populated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
